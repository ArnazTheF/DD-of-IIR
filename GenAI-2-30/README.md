# Калькулятор косинусной близости

Этот Python-скрипт вычисляет матрицы косинусной близости между предложениями с использованием двух методов эмбеддингов: Sentence Transformers (на основе BERT) и Word2Vec (с усреднением векторов слов). Он генерирует интерактивные тепловые карты с помощью Plotly для визуализации и логирует оценки близости. Скрипт предназначен для сравнения семантических сходств в задачах обработки естественного языка.

## Возможности
- Поддерживает два метода эмбеддингов: 'transformer' (используя Sentence-BERT) и 'word2vec'.
- Обрабатывает входные данные из списка предложений или файла .txt (ограничено ровно 3 предложениями для простоты).
- Выводит интерактивные HTML-файлы с тепловыми картами матриц косинусной близости.
- Логирует подробные оценки близости между парами предложений.
- Обработка ошибок и логирование для надежности.

## Установка

Чтобы настроить среду, клонируйте репозиторий и установите необходимые зависимости.

### Требования
Установите зависимости с помощью pip:

```bash
pip install -r requirements.txt
```

**Примечание:** Убедитесь, что у вас есть предварительно обученная модель Word2Vec с именем `word2vec.model` в той же директории, где находится скрипт (или укажите правильный путь в коде). Эта модель предполагается обученной в рамках связанных задач (см. раздел "Связанные задачи").

## Использование

### Запуск скрипта
1. Поместите предложения в файл `.txt` (по одному предложению на строку, ровно 3 предложения) или используйте встроенные в скрипт предложения по умолчанию.
2. Установите константы в начале скрипта:
   - `SENTENCES_FILE`: Путь к входному файлу .txt (или `None` для использования значений по умолчанию).
   - `OUTPUT_DIR`: Директория для сохранения выходных HTML-файлов (по умолчанию: текущая директория).
3. Запустите скрипт:

```bash
python cosine_similarity.py
```

Скрипт:
- Вычислит близость с использованием обоих методов.
- Сохранит два HTML-файла: `sim_matrix_transformer.html` и `sim_matrix_word2vec.html`.
- Выведет в консоль логи с оценками близости.

В случае ошибок (например, отсутствие модели или некорректный ввод) скрипт запишет их в лог и завершится с кодом 1.

## Просмотр матриц косинусной близости

После выполнения скрипта:
- Откройте сгенерированные HTML-файлы (`sim_matrix_transformer.html` и `sim_matrix_word2vec.html`) в любом веб-браузере.
- Эти файлы представляют собой интерактивные тепловые карты Plotly, отображающие матрицу косинусной близости.
  - Оси X и Y обозначают предложения (например, "Предложение 1", "Предложение 2").
  - Цветовая шкала варьируется от -1 (разные) до 1 (идентичные), с использованием градиента желто-зелено-голубого цвета.
  - Наведите курсор на ячейки, чтобы увидеть точные значения.
- Логи в консоли отобразят парные значения близости (исключая сравнения предложения с самим собой) для быстрого просмотра.

## Связанные задачи

Этот скрипт основывается на предыдущих задачах из раздела GenAI:
- **GenAI-1-26**: Использует предварительно обученную модель Word2Vec (`word2vec.model`), загруженную из этой задачи для создания эмбеддингов слов.
- **GenAI-1-30**: Реализует алгоритм косинусной близости между предложениями, расширяя методы измерения расстояний, представленные в этой задаче.

## Пример вывода

Для встроенных в скрипт предложений:

```python
sentences = [
    "Cosine similarity measures the angle between two vectors to determine their similarity",
    "Deep learning is a subset of Machine Learning.",
    "Machine learning models require large datasets to achieve high accuracy"
]
```

### Логированные значения близости

Для метода **transformer** (Sentence-BERT):
```
2025-09-25 01:44:32,880 - INFO - Cosine similarity matrix calculated using transformer:
2025-09-25 01:44:32,880 - INFO - Sentence 1 vs Sentence 2: 0.0541
2025-09-25 01:44:32,881 - INFO - Sentence 1 vs Sentence 3: 0.0161
2025-09-25 01:44:32,881 - INFO - Sentence 2 vs Sentence 1: 0.0541
2025-09-25 01:44:32,881 - INFO - Sentence 2 vs Sentence 3: 0.4980
2025-09-25 01:44:32,881 - INFO - Sentence 3 vs Sentence 1: 0.0161
2025-09-25 01:44:32,881 - INFO - Sentence 3 vs Sentence 2: 0.4980
```

Для метода **word2vec** (с усреднением слов):
```
2025-09-25 01:44:33,019 - INFO - Cosine similarity matrix calculated using word2vec:
2025-09-25 01:44:33,019 - INFO - Sentence 1 vs Sentence 2: 0.2442
2025-09-25 01:44:33,019 - INFO - Sentence 1 vs Sentence 3: 0.3560
2025-09-25 01:44:33,020 - INFO - Sentence 2 vs Sentence 1: 0.2442
2025-09-25 01:44:33,020 - INFO - Sentence 2 vs Sentence 3: 0.7697
2025-09-25 01:44:33,020 - INFO - Sentence 3 vs Sentence 1: 0.3560
2025-09-25 01:44:33,020 - INFO - Sentence 3 vs Sentence 2: 0.7697
```

### Объяснение результатов
В данном примере метод Sentence-BERT (transformer) демонстрирует более точные семантические оценки близости по сравнению с Word2Vec с простым усреднением слов. Вот почему:

- **Предложение 1 vs Предложение 2**: Предложение 1 описывает косинусную близость (математическая концепция), а Предложение 2 говорит о глубоком обучении как подмножестве машинного обучения. Они имеют минимальное семантическое пересечение. Transformer дает низкую оценку (0.0541), правильно определяя низкую схожесть. Word2Vec завышает оценку (0.2442) из-за общих слов, таких как "learning", без учета полного контекста.

- **Предложение 1 vs Предложение 3**: Предложение 3 касается требований к данным для машинного обучения, что не связано с косинусной близостью. Transformer присваивает очень низкую оценку (0.0161), отражая низкую релевантность. Word2Vec завышает (0.3560) из-за поверхностных совпадений слов (например, "models", "vectors").

- **Предложение 2 vs Предложение 3**: Оба предложения связаны с машинным обучением (одно о подмножествах, другое о потребностях в данных), поэтому они должны показывать умеренную или высокую схожесть. Transformer дает сбалансированную оценку 0.4980, указывая на связь, но не идентичность. Word2Vec переоценивает (0.7697), считая их очень похожими из-за повторяющихся терминов, таких как "machine learning", без тонкого понимания.

В целом, Sentence-BERT превосходит Word2Vec, поскольку использует двунаправленные трансформеры для целостного кодирования предложений, улавливая контекстные связи, синтаксис и семантику. Напротив, Word2Vec усредняет векторы отдельных слов, теряя структуру уровня предложения и приводя к завышенным или неточным оценкам для непохожих пар. Это делает эмбеддинги на основе трансформеров предпочтительными для задач, требующих глубокого семантического анализа.
